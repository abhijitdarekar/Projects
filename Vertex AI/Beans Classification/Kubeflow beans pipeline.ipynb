{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fff928e-0734-4908-9f3c-324869a30b3a",
   "metadata": {},
   "source": [
    "### Vertex AI with kubeflow implementation - Basic\n",
    "\n",
    "Steps for implementation:\n",
    "1. Set up all the neasseary api's (Aiplatform, Container Registery and Compute  )\n",
    "    You can do this by going using Console or using Google shell\n",
    "2. Look for API's such as \n",
    "    - Compute API\n",
    "    - Container Registery\n",
    "    - AI Platform\n",
    "3. If you want to enable api's from shell run the below command in shell\n",
    "    - `gcloud servicea enable compute.googleapis.com`\n",
    "    - `gcloud servicea enable aiplaform.googleapis.com`\n",
    "    - `gcloud servicea enable containerregistery.googleapis.com`\n",
    "\n",
    "4. Create a bucket, either from gcloud console or gcloud shell using below command\n",
    "    - `gsutil mb -l '<location>'  <BUCKET_NAME> ` \n",
    "\n",
    "5. Assign relevent IAM permissions to bucket for serviceAccount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb61fda4-3aef-4cf2-9d79-4362779feeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import compiler, dsl\n",
    "from kfp.dsl import  component, Dataset, Input, Metrics, \\\n",
    "Model, Output, OutputPath, InputPath, pipeline, Artifact\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "from google.cloud import aiplatform_v1\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55c78aac-9511-4ae0-bfc3-1285ea281e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q --user kfp\n",
    "import kfp\n",
    "kfp.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef68431-a829-47d9-a8a3-4aa2d6ba9fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID=\"\"\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_out = !gcloud config list --format 'value(core.project)'\n",
    "    PROJECT_ID = shell_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa71260c-d80d-46f9-b8ee-443e05bf36e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"gs://absolute-water-398310-2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7647bf76-4f92-495b-b12f-0ac6329a8332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://absolute-water-398310-2/\n",
      "gs://absolute-water-398310-bucket/\n"
     ]
    }
   ],
   "source": [
    "# Listing Bucket\n",
    "!gcloud storage ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "601fe54e-3ce2-44f0-9581-92337ef0fd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/jupyter/.local/bin\n"
     ]
    }
   ],
   "source": [
    "PATH = %env PATH\n",
    "%env PATH = {PATH}:/home/jupyter/.local/bin\n",
    "REGION = \"US-central1\"\n",
    "\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline/root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60abbf75-d6a1-4f10-97cd-d8233c21cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-bigquery\", \"pandas\", \"pyarrow\", \"db-dtypes\",\"packaging\",'google-resumable-media'],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"create_dataset.yaml\",\n",
    "\n",
    ")\n",
    "def get_dataframe_func(\n",
    "    bq_table: str,\n",
    "    output_data_path: OutputPath(\"Dataset\"),\n",
    "    \n",
    "):\n",
    "    from google.cloud import bigquery\n",
    "    import pandas as pd\n",
    "    import os\n",
    "\n",
    "    project_number = os.environ[\"CLOUD_ML_PROJECT_ID\"]\n",
    "    bqclient = bigquery.Client(project=project_number)\n",
    "    table = bigquery.TableReference.from_string(\n",
    "        bq_table\n",
    "    )\n",
    "    rows = bqclient.list_rows(\n",
    "        table\n",
    "    )\n",
    "    dataframe = rows.to_dataframe(\n",
    "        create_bqstorage_client=True,\n",
    "    )\n",
    "    dataframe = dataframe.sample(frac=1, random_state=2)\n",
    "    dataframe.to_csv(output_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf322d2c-ced4-419e-b7f8-9b452119269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@component(\n",
    "    packages_to_install=[\"sklearn\",\"pandas\",'joblib','db-dtypes'],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"beans_model_component.yaml\",\n",
    ")\n",
    "def sklearn_train(\n",
    "    dataset : Input[Dataset],\n",
    "    metrics: Output[Metrics],\n",
    "    model : Output[Model]\n",
    "):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.metrics import roc_curve\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from joblib import dump\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    df = pd.read_csv(dataset.path)\n",
    "    labels = df.pop(\"Class\").tolist()\n",
    "    data = df.values.tolist()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels)\n",
    "    \n",
    "    skmodel = DecisionTreeClassifier()\n",
    "    skmodel.fit(X_train, X_test)\n",
    "    score  = skmodel.score(X_test, y_test)\n",
    "    print('accuracy is :', score)\n",
    "    \n",
    "    metrics.log_metric(\"accuracy\",(score * 100.0))\n",
    "    metrics.log_metric(\"framework\", \"Scikit Learn\")\n",
    "    metrics.log_metric(\"dataset_size\", len(df))\n",
    "    dump(skmodel, model.path + \".joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05727608-a49a-4198-a5e8-4897f910c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=['google-cloud-aiplatform'],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file='beans_deploy_component.yaml',\n",
    ")\n",
    "def deploy_model(\n",
    "    model: Input[Model],\n",
    "    project:str,\n",
    "    region: str,\n",
    "    vertex_endpoint : Output[Artifact],\n",
    "    vertex_model : Output[Model]\n",
    "):\n",
    "    from goole.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    deployed_model = aiplatform.Model.upload(\n",
    "        artifact_uri = model.uri.replace(\"model\",\"\"),\n",
    "        display_name = 'beans_model_pipeline',\n",
    "        serving_container_image_uri = 'us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest',\n",
    "    )\n",
    "    endpoint = deployed_model.deploy(machine_type=\"n1-standard-4\")\n",
    "    \n",
    "    vertex_endpoint.uri = endpoint.resource_name\n",
    "    vertex_model.uri  = deployed_model.resource_name\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3080c355-6a60-42a8-8439-207cb777bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    name=\"mlmd-pipeline\",\n",
    "    display_name = 'mlmd-pipeline'\n",
    ")\n",
    "def pipeline_fun(\n",
    "    bq_table: str = \"\",\n",
    "    output_data_path: str = \"data.csv\",\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION\n",
    "):\n",
    "    bq_table=\"\"\n",
    "    dataset_task = get_dataframe_func(bq_table=bq_table)\n",
    "\n",
    "    model_task = sklearn_train(\n",
    "        dataset=dataset_task.output\n",
    "    )\n",
    "\n",
    "    deploy_task = deploy_model(\n",
    "        model=model_task.outputs[\"model\"],\n",
    "        project=project,\n",
    "        region=region\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57ae83bf-ede6-4c9d-8ca0-4818c80ad3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline_fun, package_path='initail_pipeline.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae194932-c080-47f8-ac97-7e0b4de836b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pipeline\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "run1 = aiplatform.PipelineJob(display_name=\"beans_pipeline\",\n",
    "                              template_path = \"initail_pipeline.json\",\n",
    "                              job_id = 'mldm-pipeline-small-{0}'.format(TIMESTAMP),\n",
    "                              parameter_values={\n",
    "                                  \"bq_table\" :\"sara-vertex-demos.beans_demo.small_dataset\"\n",
    "                              },\n",
    "                              enable_caching=True\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a30ec1ed-c761-47c5-872f-e5a8fb223eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "run1.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63b1aa6-391f-4e65-aad0-d62a62f81406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
