# PIPELINE DEFINITION
# Name: deploy-model
# Inputs:
#    model: system.Model
#    project: str
#    region: str
# Outputs:
#    vertex_endpoint: system.Artifact
#    vertex_model: system.Model
components:
  comp-deploy-model:
    executorLabel: exec-deploy-model
    inputDefinitions:
      artifacts:
        model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
      parameters:
        project:
          parameterType: STRING
        region:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        vertex_endpoint:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        vertex_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-deploy-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - deploy_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-aiplatform'\
          \ 'kfp==2.0.1' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)

          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          python3 -m kfp.components.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef deploy_model(\n    model: Input[Model],\n    project: str,\n\
          \    region: str,\n    vertex_endpoint: Output[Artifact],\n    vertex_model:\
          \ Output[Model]\n):\n    from google.cloud import aiplatform\n\n    aiplatform.init(project=project,\
          \ location=region)\n\n    deployed_model = aiplatform.Model.upload(\n  \
          \      display_name=\"beans-model-pipeline\",\n        artifact_uri = model.uri.replace(\"\
          model\", \"\"),\n        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\"\
          \n    )\n    endpoint = deployed_model.deploy(machine_type=\"n1-standard-4\"\
          )\n\n    # Save data to the output params\n    vertex_endpoint.uri = endpoint.resource_name\n\
          \    vertex_model.uri = deployed_model.resource_name\n\n"
        image: python:3.9
pipelineInfo:
  name: deploy-model
root:
  dag:
    outputs:
      artifacts:
        vertex_endpoint:
          artifactSelectors:
          - outputArtifactKey: vertex_endpoint
            producerSubtask: deploy-model
        vertex_model:
          artifactSelectors:
          - outputArtifactKey: vertex_model
            producerSubtask: deploy-model
    tasks:
      deploy-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-deploy-model
        inputs:
          artifacts:
            model:
              componentInputArtifact: model
          parameters:
            project:
              componentInputParameter: project
            region:
              componentInputParameter: region
        taskInfo:
          name: deploy-model
  inputDefinitions:
    artifacts:
      model:
        artifactType:
          schemaTitle: system.Model
          schemaVersion: 0.0.1
    parameters:
      project:
        parameterType: STRING
      region:
        parameterType: STRING
  outputDefinitions:
    artifacts:
      vertex_endpoint:
        artifactType:
          schemaTitle: system.Artifact
          schemaVersion: 0.0.1
      vertex_model:
        artifactType:
          schemaTitle: system.Model
          schemaVersion: 0.0.1
schemaVersion: 2.1.0
sdkVersion: kfp-2.0.1
